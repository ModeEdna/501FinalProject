{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wikipedia Crawl example\n",
    "\n",
    "Author: J. Hickman\n",
    "\n",
    "- This code crawls through wikipedia to get a bunch of text data\n",
    "- The code lets the user specify search category topics.\n",
    "  - The more different the topics are, the easier the classification will be.\n",
    "  - For example, i used (pizza, metallurgy, basketball)\n",
    "- It then searches wikipedia for articles related to these topics\n",
    "- Loops over the wikipedia pages and gets the text from the wikipedia pages\n",
    "- Breaks the text into chunks (based on a user input specifying the number of sentences per chunk)\n",
    "- Each chunk is cleaned and tagged with a \"label\" (classification) and a numeric \"sentiment score\" (regression)\n",
    "- These cleaned chunks form a corpus of strings with associated tags\n",
    "\n",
    "```\n",
    "python -m pip install wikipedia_sections\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/modeedna/opt/anaconda3/envs/ANLY501/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "# conda install -c conda-forge wikipedia\n",
    "# conda install -c conda-forge wordcloud\n",
    "# pip install wikipedia_sections\n",
    "\n",
    "import wikipedia\n",
    "import nltk\n",
    "import string \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/modeedna/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/modeedna/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/modeedna/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/modeedna/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/modeedna/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RUN THE FOLLOWING IF YOU HAVEN'T DOWNLOADED THESE BEFORE\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set user parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS \n",
    "label_list=['FIFA World Cup','FIFA Champion','FIFA Ranking']\n",
    "max_num_pages=25\n",
    "sentence_per_chunk=5\n",
    "min_sentence_length=20\n",
    "\n",
    "# GET STOPWORDS\n",
    "# from nltk.corpus import stopwords\n",
    "stop_words=nltk.corpus.stopwords.words('english')\n",
    "\n",
    "# INITALIZE STEMMER+LEMITZIZER+SIA\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define text cleaning function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_string(text):\n",
    "\t# #FILTER OUT UNWANTED CHAR\n",
    "\tnew_text=\"\"\n",
    "\t# keep=string.printable\n",
    "\tkeep=\" abcdefghijklmnopqrstuvwxyz0123456789\"\n",
    "\tfor character in text:\n",
    "\t\tif character.lower() in keep:\n",
    "\t\t\tnew_text+=character.lower()\n",
    "\t\telse: \n",
    "\t\t\tnew_text+=\" \"\n",
    "\ttext=new_text\n",
    "\t# print(text)\n",
    "\n",
    "\t# #FILTER OUT UNWANTED WORDS\n",
    "\tnew_text=\"\"\n",
    "\tfor word in nltk.tokenize.word_tokenize(text):\n",
    "\t\tif word not in nltk.corpus.stopwords.words('english'):\n",
    "\t\t\t#lemmatize \n",
    "\t\t\ttmp=lemmatizer.lemmatize(word)\n",
    "\t\t\t# tmp=stemmer.stem(tmp)\n",
    "\n",
    "\t\t\t# update word if there is a change\n",
    "\t\t\t# if(tmp!=word): print(tmp,word)\n",
    "\t\t\t\n",
    "\t\t\tword=tmp\n",
    "\t\t\tif len(word)>1:\n",
    "\t\t\t\tif word in [\".\",\",\",\"!\",\"?\",\":\",\";\"]:\n",
    "\t\t\t\t\t#remove the last space\n",
    "\t\t\t\t\tnew_text=new_text[0:-1]+word+\" \"\n",
    "\t\t\t\telse: #add a space\n",
    "\t\t\t\t\tnew_text+=word.lower()+\" \"\n",
    "\ttext=new_text.strip()\n",
    "\treturn text\n",
    "\n",
    "#clean_string('the word \"pizza\" first appeared in a Latin text from the town of Gaeta, then still part of the Byzantine Empire, in 997 AD; the text states that a tenant of certain property is to give the bishop of Gaeta duodecim pizze (\"twelve pizzas\") every Christmas Day, and another twelve every Easter Sunday.Suggested etymologies include:')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preform a wikipedia crawl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pages for label = FIFA World Cup : ['FIFA World Cup', '2018 FIFA World Cup', '2022 FIFA World Cup', '2014 FIFA World Cup', '2010 FIFA World Cup', '2026 FIFA World Cup', '2030 FIFA World Cup', '2006 FIFA World Cup', '2002 FIFA World Cup', 'List of FIFA World Cup finals', '1998 FIFA World Cup', \"2023 FIFA Women's World Cup\", 'FIFA Club World Cup', 'FIFA World Cup awards', 'FIFA World Cup hosts', '1994 FIFA World Cup', \"FIFA Women's World Cup\", 'FIFA U-20 World Cup', '2034 FIFA World Cup', '2026 FIFA World Cup qualification', '1990 FIFA World Cup', '1930 FIFA World Cup', \"FIFA Men's World Ranking\", '1986 FIFA World Cup', 'List of FIFA World Cup anthems and songs']\n",
      "\t FIFA World Cup\n",
      "\t 2018 FIFA World Cup\n",
      "\t 2022 FIFA World Cup\n",
      "\t 2014 FIFA World Cup\n",
      "\t 2010 FIFA World Cup\n",
      "\t 2026 FIFA World Cup\n",
      "\t 2030 FIFA World Cup\n",
      "\t 2006 FIFA World Cup\n",
      "\t 2002 FIFA World Cup\n",
      "\t List of FIFA World Cup finals\n",
      "\t 1998 FIFA World Cup\n",
      "\t 2023 FIFA Women's World Cup\n",
      "\t FIFA Club World Cup\n",
      "\t FIFA World Cup awards\n",
      "\t FIFA World Cup hosts\n",
      "\t 1994 FIFA World Cup\n",
      "WARNING: SOMETHING WENT WRONG: 1994 FIFA World Cup\n",
      "\t FIFA Women's World Cup\n",
      "\t FIFA U-20 World Cup\n",
      "WARNING: SOMETHING WENT WRONG: FIFA U-20 World Cup\n",
      "\t 2034 FIFA World Cup\n",
      "\t 2026 FIFA World Cup qualification\n",
      "WARNING: SOMETHING WENT WRONG: 2026 FIFA World Cup qualification\n",
      "\t 1990 FIFA World Cup\n",
      "WARNING: SOMETHING WENT WRONG: 1990 FIFA World Cup\n",
      "\t 1930 FIFA World Cup\n",
      "WARNING: SOMETHING WENT WRONG: 1930 FIFA World Cup\n",
      "\t FIFA Men's World Ranking\n",
      "\t 1986 FIFA World Cup\n",
      "WARNING: SOMETHING WENT WRONG: 1986 FIFA World Cup\n",
      "\t List of FIFA World Cup anthems and songs\n",
      "Pages for label = FIFA Champion : ['List of FIFA World Cup finals', 'FIFA Club World Cup', 'FIFA Champions Badge', '2024 FIFA Futsal World Cup', 'FIFA (video game series)', 'FIFA World Cup', 'FIFA', \"FIFA Women's World Cup\", 'FIFA Futsal World Cup', 'FIFA Confederations Cup', \"FIFA Men's World Ranking\", 'FIFA U-17 World Cup', 'List of FIFA Club World Cup finals', \"FIFA U-17 Women's World Cup\", 'FIFA U-20 World Cup', 'List of FIFA country codes', 'FIFA Player of the Century', \"2023 FIFA Women's World Cup\", 'List of presidents of FIFA', '2018 FIFA World Cup', '2022 FIFA World Cup', 'The Best FIFA Football Awards', \"The Best FIFA Men's Player\", '2014 FIFA World Cup', 'FIFA 23']\n",
      "\t List of FIFA World Cup finals\n",
      "\t FIFA Club World Cup\n",
      "\t FIFA Champions Badge\n",
      "\t 2024 FIFA Futsal World Cup\n",
      "WARNING: SOMETHING WENT WRONG: 2024 FIFA Futsal World Cup\n",
      "\t FIFA (video game series)\n",
      "WARNING: SOMETHING WENT WRONG: FIFA (video game series)\n",
      "\t FIFA World Cup\n",
      "\t FIFA\n",
      "WARNING: SOMETHING WENT WRONG: FIFA\n",
      "\t FIFA Women's World Cup\n",
      "\t FIFA Futsal World Cup\n",
      "\t FIFA Confederations Cup\n",
      "\t FIFA Men's World Ranking\n",
      "\t FIFA U-17 World Cup\n",
      "\t List of FIFA Club World Cup finals\n",
      "\t FIFA U-17 Women's World Cup\n",
      "\t FIFA U-20 World Cup\n",
      "WARNING: SOMETHING WENT WRONG: FIFA U-20 World Cup\n",
      "\t List of FIFA country codes\n",
      "\t FIFA Player of the Century\n",
      "\t 2023 FIFA Women's World Cup\n",
      "\t List of presidents of FIFA\n",
      "\t 2018 FIFA World Cup\n",
      "\t 2022 FIFA World Cup\n",
      "\t The Best FIFA Football Awards\n",
      "\t The Best FIFA Men's Player\n",
      "\t 2014 FIFA World Cup\n",
      "\t FIFA 23\n",
      "Pages for label = FIFA Ranking : [\"FIFA Men's World Ranking\", \"FIFA Women's World Rankings\", '2021 FIFA Arab Cup', 'FIFA (video game series)', 'Belgium national football team', '2006 FIFA World Cup', 'Northern Ireland national football team', 'New Zealand national football team', 'Bosnia and Herzegovina national football team', 'Netherlands national football team', 'FIFA World Ranking system (2006–2018)', 'FIFA', 'India national football team', 'Croatia national football team', '2022 FIFA World Cup qualification', 'Iran national futsal team', 'CAF 5-Year Ranking', 'Central African Republic national football team', '2023 AFC Asian Cup', 'Iceland national football team', 'Uzbekistan national futsal team', 'UEFA coefficient', '2014 FIFA World Cup', 'Asian Football Confederation', 'Wales national football team']\n",
      "\t FIFA Men's World Ranking\n",
      "\t FIFA Women's World Rankings\n",
      "\t 2021 FIFA Arab Cup\n",
      "\t FIFA (video game series)\n",
      "WARNING: SOMETHING WENT WRONG: FIFA (video game series)\n",
      "\t Belgium national football team\n",
      "\t 2006 FIFA World Cup\n",
      "\t Northern Ireland national football team\n",
      "\t New Zealand national football team\n",
      "\t Bosnia and Herzegovina national football team\n",
      "\t Netherlands national football team\n",
      "\t FIFA World Ranking system (2006–2018)\n",
      "\t FIFA\n",
      "WARNING: SOMETHING WENT WRONG: FIFA\n",
      "\t India national football team\n",
      "\t Croatia national football team\n",
      "\t 2022 FIFA World Cup qualification\n",
      "WARNING: SOMETHING WENT WRONG: 2022 FIFA World Cup qualification\n",
      "\t Iran national futsal team\n",
      "\t CAF 5-Year Ranking\n",
      "\t Central African Republic national football team\n",
      "WARNING: SOMETHING WENT WRONG: Central African Republic national football team\n",
      "\t 2023 AFC Asian Cup\n",
      "WARNING: SOMETHING WENT WRONG: 2023 AFC Asian Cup\n",
      "\t Iceland national football team\n",
      "WARNING: SOMETHING WENT WRONG: Iceland national football team\n",
      "\t Uzbekistan national futsal team\n",
      "\t UEFA coefficient\n",
      "\t 2014 FIFA World Cup\n",
      "\t Asian Football Confederation\n",
      "\t Wales national football team\n"
     ]
    }
   ],
   "source": [
    "#INITIALIZE \n",
    "corpus=[]  # list of strings (input variables X)\n",
    "targets=[] # list of targets (labels or response variables Y)\n",
    "\n",
    "#--------------------------\n",
    "# LOOP OVER TOPICS \n",
    "#--------------------------\n",
    "for label in label_list:\n",
    "\n",
    "\t#SEARCH FOR RELEVANT PAGES \n",
    "\ttitles=wikipedia.search(label,results=max_num_pages)\n",
    "\tprint(\"Pages for label =\",label,\":\",titles)\n",
    "\n",
    "\t#LOOP OVER WIKI-PAGES\n",
    "\tfor title in titles:\n",
    "\t\ttry:\n",
    "\t\t\tprint(\"\t\",title)\n",
    "\t\t\twiki_page = wikipedia.page(title, auto_suggest=True)\n",
    "\n",
    "\t\t\t# LOOP OVER SECTIONS IN ARTICLE AND GET PAGE TEXT\n",
    "\t\t\tfor section in wiki_page.sections:\n",
    "\t\t\t\ttext=wiki_page.section(section); #print(text)\n",
    "\n",
    "\t\t\t\t#BREAK IN TO SENTANCES \n",
    "\t\t\t\tsentences=nltk.tokenize.sent_tokenize(text)\n",
    "\t\t\t\tcounter=0\n",
    "\t\t\t\ttext_chunk=''\n",
    "\n",
    "\t\t\t\t#LOOP OVER SENTENCES \n",
    "\t\t\t\tfor sentence in sentences:\n",
    "\t\t\t\t\tif len(sentence)>min_sentence_length:\n",
    "\t\t\t\t\t\tif(counter%sentence_per_chunk==0 and counter!=0):\n",
    "\t\t\t\t\t\t\t# PROCESS COMPLETED CHUNK \n",
    "\t\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t\t# CLEAN STRING\n",
    "\t\t\t\t\t\t\ttext_chunk=clean_string(text_chunk)\n",
    "\n",
    "\t\t\t\t\t\t\t# REMOVE LABEL IF IN STRING (MAKES IT TOO EASY)\n",
    "\t\t\t\t\t\t\ttext_chunk=text_chunk.replace(label,\"\")\n",
    "\t\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t\t# REMOVE ANY DOUBLE SPACES\n",
    "\t\t\t\t\t\t\ttext_chunk=' '.join(text_chunk.split()).strip()\n",
    "\n",
    "\t\t\t\t\t\t\t#UPDATE CORPUS \n",
    "\t\t\t\t\t\t\tcorpus.append(text_chunk)\n",
    "\n",
    "\t\t\t\t\t\t\t#UPDATE TARGETS\n",
    "\t\t\t\t\t\t\tscore=sia.polarity_scores(text_chunk)\n",
    "\t\t\t\t\t\t\ttarget=[label,score['compound']]\n",
    "\t\t\t\t\t\t\ttargets.append(target)\n",
    "\n",
    "\t\t\t\t\t\t\t#print(\"TEXT\\n\",text_chunk,target)\n",
    "\n",
    "\t\t\t\t\t\t\t# RESET CHUNK FOR NEXT ITERATION \n",
    "\t\t\t\t\t\t\ttext_chunk=sentence\n",
    "\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\ttext_chunk+=sentence\n",
    "\t\t\t\t\t\t#print(\"--------\\n\", sentence)\n",
    "\t\t\t\t\t\tcounter+=1\n",
    "\n",
    "\t\texcept:\n",
    "\t\t\tprint(\"WARNING: SOMETHING WENT WRONG:\", title);  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of text chunks =  727\n",
      "number of targets =  727\n",
      "                                                  text           label  \\\n",
      "0    world first international football match chall...  FIFA World Cup   \n",
      "1    great britain represented england national ama...  FIFA World Cup   \n",
      "2    west auckland tournament returned 1911 success...  FIFA World Cup   \n",
      "3    due success olympic football tournament fifa p...  FIFA World Cup   \n",
      "4    total 13 nation took part seven south america ...  FIFA World Cup   \n",
      "..                                                 ...             ...   \n",
      "722  2022 world cup qualification wale drawn group ...    FIFA Ranking   \n",
      "723  primary kit long red crest football associatio...    FIFA Ranking   \n",
      "724  2000 2009 wale played home match millennium st...    FIFA Ranking   \n",
      "725  ryan giggs scored wale goal match becoming fir...    FIFA Ranking   \n",
      "726  2014 world cup qualifying campaign saw four ho...    FIFA Ranking   \n",
      "\n",
      "     sentiment  \n",
      "0       0.8360  \n",
      "1       0.8360  \n",
      "2       0.8779  \n",
      "3       0.9300  \n",
      "4      -0.0516  \n",
      "..         ...  \n",
      "722     0.7351  \n",
      "723     0.8779  \n",
      "724     0.7906  \n",
      "725     0.9638  \n",
      "726     0.8481  \n",
      "\n",
      "[727 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#SANITY CHECKS AND PRINT TO FILE \n",
    "print(\"number of text chunks = \",len(corpus))\n",
    "print(\"number of targets = \",len(targets))\n",
    "\n",
    "tmp=[]\n",
    "for i in range(0,len(corpus)):\n",
    "    tmp.append([corpus[i],targets[i][0],targets[i][1]])\n",
    "df=pd.DataFrame(tmp)\n",
    "df=df.rename(columns={0: \"text\", 1: \"label\", 2: \"sentiment\"})\n",
    "print(df)\n",
    "df.to_csv('wiki-crawl-results.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #RELOAD FILE AND PRETEND THAT IS OUR STARTING POINT \n",
    "# df=pd.read_csv('wiki-crawl-results.csv')  \n",
    "# #print(df)\n",
    "\n",
    "# #CONVERT FROM STRING LABELS TO INTEGERS \n",
    "# labels=[]; #y1=[]; y2=[]\n",
    "# y1=[]\n",
    "# for label in df[\"label\"]:\n",
    "#     if label not in labels:\n",
    "#         labels.append(label)\n",
    "#         print(\"index =\",len(labels)-1,\": label =\",label)\n",
    "#     for i in range(0,len(labels)):\n",
    "#         if(label==labels[i]):\n",
    "#             y1.append(i)\n",
    "# y1=np.array(y1)\n",
    "\n",
    "# # CONVERT DF TO LIST OF STRINGS \n",
    "# corpus=df[\"text\"].to_list()\n",
    "# y2=df[\"sentiment\"].to_numpy()\n",
    "\n",
    "# print(\"number of text chunks = \",len(corpus))\n",
    "# print(len(y1))\n",
    "# print(corpus[0:3])\n",
    "\n",
    "# # INITIALIZE COUNT VECTORIZER\n",
    "# vectorizer=CountVectorizer()   \n",
    "\n",
    "# # RUN COUNT VECTORIZER ON OUR COURPUS \n",
    "# Xs  =  vectorizer.fit_transform(corpus)   \n",
    "# X=np.array(Xs.todense())\n",
    "\n",
    "# #CONVERT TO ONE-HOT VECTORS\n",
    "# maxs=np.max(X,axis=0)\n",
    "# X=np.ceil(X/maxs)\n",
    "\n",
    "# # DOUBLE CHECK \n",
    "# print(X.shape,y1.shape,y2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('ANLY501')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6c72976fb237423a2a1d3151ac569995244a4a767dd0452f9a8ae3f982e3763a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
